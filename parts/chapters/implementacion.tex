% !TEX root = ../../proyect.tex

\chapter{Implementación}\label{implementacion}
\section{Tecnologías}\label{sec:tecnologias}

A continuación se definirán las tecnologías usadas para llevar a cabo el Producto Mínimo Viable.

\subsubsection{\textit{Web Scrapping}}
El aspecto fundamental del producto es la recolección de noticias de periódicos. Esta, como se ha ido diciendo a lo largo del documento, se realiza a través de RSS. Sin esta característica, no tendría utilidad la aplicación. Sin embargo, con esto solo, el aplicativo se vería inútil. Normalmente, cada medio solo publica un titular y una pequeña descripción vía RSS. Esto les sirve de gancho al usuario para que pase del lector de sindicación de contenido a la web de su medio.

Como se ha dicho, otro pilar fundamental para el buen funcionamiento del producto es el análisis de noticias. Por tanto, si no se posee más que un pequeño texto acompañado de cada noticia, poco podrá aportar este. Es por ello imprescindible conseguir el texto original del artículo para poder procesarlo correctamente. Dado que los medios no poseen esta característica, hemos de realizarla a través del \textit{Web Scrapping}.

El \textit{Web Scrapping} es una técnica que permite extraer información de cualquier sitio en Internet de forma automática. La información en la web se encuentra en diferentes formatos dependiendo de su misión para con el receptor. Resumidamente se encuentran dos tipos de datos: estructurados, como pueden ser ficheros XML o APIs, y no estructurados, como los ficheros HTML. Estos últimos abundan ya que, en un principio, van destinados al usuario final directamente, con la idea de ser leídos o vistos sin más.

\figura{0.75}{img/desarrollo/web_scrapping}{Muestra del \textit{Web Scrapping}}{fig:web_scrapping}{}

Por lo dicho, esta técnica posee diferentes implementaciones, dependiendo del nivel de automatización que se desee. Un primer nivel sería el de extraer el fichero HTML y trabajar con él, utilizando, por ejemplo, expresiones regulares; otro sería utilizar parsers o minería de datos, para extraer el contenido principal; y otro, el de analizar una página en concreto, para saber cómo se estructura el contenido realmente interesante y conociendo dicho patrón, aplicarlo correctamente.

Como última consideración, se ha informar que antes de trabajar con la información extraída del \textit{Web Scrapping}, hay que saber que esta tiene implicaciones legales. Estas, en la mayoría de los casos, se encuentran en un vacío legal. Esto es debido a lo delicado del tema, en cuanto a jurisdicción, responsabilidad y autoridad de dichas fuentes.

En la práctica, si los datos se usan para un uso personal, no hay problema añadido. La cosa cambia si es para un tratamiento comercial. De hecho, actualmente, hay varios juicios en curso por un uso fraudulento de esta técnica en Australia o Estados Unidos, como se puede ver en el artículo publicado por \citeA{web_scrapping}.

\subsubsection{Recuperación de información}
Una vez extraída la información de los medios, es imprescindible tratarla correctamente. No basta el guardarla en una base de datos sin más, sino que se hace necesario usar medios especializados para ello para albergar las. Si se usan, por ello, técnicas de Búsqueda y Recuperación de Información (ISR, por sus siglas en inglés, en adelante) es posible tratar cada noticia como un documento y así extraer metadatos de cada una.

\figura{0.75}{img/desarrollo/information_retrieval}{Muestra de Recuperación de Información}{fig:information_retrieval}{}

Esta técnica, por tanto, permite recuperar documentos en base a búsqueda de sus metadatos guardados en un índice. Esta información no suele estar estructurada al uso y su misión es la de buscar información relevante en base a diferentes filtros. Hay diferentes técnicas, dependiendo del grado de exactitud que se requiera, en base a la naturaleza de la consulta. Algunas de las más importantes son las siguientes.

\begin{itemize}
    \item \textbf{Sistemas de recuperación de lógica difusa}: las búsquedas sobre la información son de tipo fuzzy, es decir, frases y oraciones normales en lenguaje humano, que el sistema transforma en sentencias lógicas. Así, la información que se consigue, se basa en proposiciones, teniendo en cuenta si los términos buscados aparecen o no.
    \item \textbf{Técnicas de ponderación de términos}: dado que hay términos de búsqueda que tienen más relevancia que otros, es lógico que se pondere dichos términos sobre el resto. Así, los documentos más relevantes, serán los que contengan el mayor número de dichos términos y que más se repitan a lo largo de su cuerpo.
    \item \textbf{Técnicas de clustering}: es un modelo probabilístico sobre la frecuencia de los términos de búsqueda. Se clasifican los documentos por valores que, finalmente, representan los pesos. Sobre esto, se hacen grupos por cercanía en significación.
    \item \textbf{Técnicas de retroalimentación por relevancia}: una vez hecha una búsqueda utilizando una de las técnicas anteriores, se vuelve a buscar pero con términos relacionados con los primeros documentos resultantes. Así, se consigue aumentar el número de documentos en la búsqueda.
    \item \textbf{Técnicas de stemming}: usa la técnica de Stemming para la búsqueda, es decir, trunca los términos de búsqueda quitando posibles prefijos o sufijos. En fin, evita ambigüedades léxicas. Así, se hacen búsqueda por significado, aunque como aproximación.
\end{itemize}

Como se puede observar, estas técnicas se pueden combinar entre sí dentro de una implementación concreta, aunque siempre el funcionamiento es el presentado en la imagen \ref{fig:information_retrieval}: se procesan los documentos, se indexan y se busca sobre el índice.

Como se ha dicho al inicio del apartado, interesa que este índice creado trate correctamente la información guardada. Esta es, por tanto, la mayor ventaja de usar un ISR: se pueden elegir técnicas y tratamientos concretos por cada campo, así como por cada índice de documentos. En el ejemplo de guardar noticias se puede decir que extraiga las palabras claves, que de más importancia al cuerpo de la noticia, que obvie mayúsculas y tildes en el índice y para el análisis, que no tenga en cuenta artículos y preposiciones.

Esto dará una versatilidad a esta \textit{base de datos no relacional} mucho mayor, ya que estará especializada en el dominio del problema concreto. Mientras tanto, en una base de datos clásica, la información se guarda siempre de manera homogénea y genérica para cualquier dato que se quiera albergar.

\subsubsection{Sistemas de recomendación}
Una vez obtenidas las noticias y analizadas y correspondientemente albergadas en el sistema, habrá que dar uso a los metadatos generados por el ISR. Esta característica, como se ha dicho a la hora de explicar el producto, será el valor diferencial a cualquier lector de noticias: la capacidad de extraer el perfil del usuario y recomendar noticias en base a sus intereses. Esto, por tanto, se consigue con un sistema de recomendación especializado.

\figura{0.5}{img/desarrollo/recommendation_system}{Muestra de sistemas de recomendación}{fig:recommendation_system}{}

Un sistema de recomendación es la técnica de filtrado de información en base a los intereses de los usuarios. En definitiva, se encarga de comparar el perfil del usuario con los ítems, en concreto para recomendarle aquellos que no conoce y podrían gustarle. Para realizar esta técnica, existe la capacidad de elección entre diversas implementaciones. Como se puede apreciar, es importante analizar tanto a usuarios como ítems a recomendar.

Analizar el perfil del usuario significa, en definitiva, extraer características de su interactuación con dichos ítems. El método de extracción de sus características puede ser implícito o explícito, dependiendo de la voluntariedad del usuario al indicar al sistema sus gustos. Dentro del primero se encuentran aquellos sistemas que solicitan al usuario que valore un determinado producto, o, directamente, seleccione sus intereses. Dentro del segundo, a aquellos en los que, en base a visitas a un ítem, al tipo de interacción con el mismo, al tiempo que está viéndolo, u otras técnicas, se saca información del usuario de manera indirecta.

Ambos tienen aspectos positivos y negativos. En el primero, el usuario dice al sistema expresamente qué le gusta o disgusta, mientras el segundo, la aplicación ha de suponerlo. Esto último puede llevar a numerosos fallos de interpretación frente a la certeza que proporciona el primero. Por otro lado, el método implícito extrae dicha información sin necesidad de la intervención del usuario, cosa que el primero no puede. Esto puede hacer que en el método explícito, los interesados nunca completen sus preferencias, por el poco uso de la aplicación, lo que conllevaría a fallos en la recomendación.

Como se podrá intuir, la mejor solución depende de la naturaleza de la aplicación y el enfoque que ponga esta en el usuario objetivo. No obstante, una buena solución podrá ser un aproximación a ambas, de forma híbrida. Con esto, se poseerá las ventajas de ambas de manera sencilla. En la siguiente imagen se puede apreciar un motor de recomendación.

\figura{0.75}{img/desarrollo/user_profile}{Muestra de extracción del perfil del usuario}{fig:user_profile}{}

Una vez obtenido el perfil del usuario, se ha de poder recomendarle ítems. En este apartado se aprecian dos enfoques mayoritarios (y un tercero, de la unión de ambos) como se puede apreciar en la imagen \ref{fig:recommendation_system}.

La primera implementación son las recomendaciones basadas en contenido. Esta técnica consiste en analizar los ítems del sistema en base a una o varias características. Así, sabiendo los ítems con los que el usuario ha interactuado, es posible recomendarle otros que posean características similares. El principal problema de este sistema de recomendación es la falta de serendipia, es decir, al usuario siempre se le muestra el mismo tipo de productos. El motivo: es la información que se tiene y sobre esta se recomienda exclusivamente. Esto conllevará un hartazgo de las recomendaciones, resultando finalmente inútiles.

La segunda implementación es el filtrado colaborativo. Esta consiste en mostrar productos que han resultado atractivos para otros usuarios con gustos similares y que todavía no ha visto. Para esto, se han de calcular similitud entre los usuarios, y no sobre los ítems, como vimos en las recomendaciones en base al contenido. El principal problema del este motor es que funcionará bien si se poseen diferentes y numerosos tipos de usuario y si se tiene de los interesados en cuestión de bastante información para tener un perfil completo. Esto es un problema, sobre todo para aplicaciones que se empiezan, lógicamente, sin afluencia.

Aquí, igual que anteriormente con el perfil del usuario, es posible combinar ambas técnicas haciendo un filtrado híbrido. Esto hará que el se contrarresten los defectos de ambas, centrándose en sus virtudes. Con respecto a la falta de serendipia, el filtro colaborativo lo supera haciendo similitud entre usuarios: un interesado puede verse sorprendido al ver que se le recomienda algo que puede ser nuevo para él. Con respecto a la comunidad necesaria inicialmente, las recomendaciones basadas en contenido lo contrarrestan por la similitud de ítems: habiendo un solo usuario, funcionarán bien las sugerencias de productos.

\section{Herramientas}\label{sec:herramientas}

Para el desarrollo del producto y, concretamente, la implementación de las tecnologías previamente mencionadas, se han usado las siguientes herramientas.

\subsection{Backend}
Para el desarrollo del servidor se han usado Python con el framework web Django, ambos en sus últimas versiones. Además, claro está, de librerías que permitan desarrollar los requisitos de la aplicación.

\subsubsection{Python}
Python es un lenguaje interpretado y multiparadigma. Esto último se debe a que soporta tanto programación orientada a objetos como imperativa, además de programación funcional. Actualmente está administrado por la fundación \textit{Python Software Foundation} y posee una licencia de código abierto denominada \textit{Python Software Foundation License}. Esta nos permite hacer modificaciones de su código fuente y la creación todo trabajo derivado de este, sin necesidad de que sea también código abierto.

Se ha decidido utilizar este lenguaje de programación en el lado del servidor debido a la cantidad y facilidad de uso de herramientas que implementan las tecnologías previamente mencionadas. Es la referencia en temas de \textit{Web Scrapping} e Inteligencia Artificial, como se puede apreciar en el artículo de \citeA{python}.

\subsubsection{Django}
Django es un framework de desarrollo web, también open source, que ofrece un marco inicial desarrollado sobre el patrón de diseño Modelo-Vista-Controlador. Siendo exactos, ya no se habla de \textit{Model-View-Controller}, sino de Modelo-Plantilla-Vista. Sin embargo, hacen referencia a los mismos conceptos. El Modelo es la capa de accesos a los datos; la Plantilla, es la capa de presentación; la Vista posee la lógica de negocio de la aplicación y, por tanto, hace de puente entre ambos. Vemos, por tanto, que esencialmente representan lo mismo.

Su misión es la facilitar la creación de aplicaciones web complejas. Su valor diferencial es su acento en la conectividad, reutilización y la extensión de todos y cada uno de sus componentes. Tiene, además, como principal característica, desde el punto de vista del desarrollo, el que todo esté hecho en Python. Esto es conocido dentro de la comunidad como desarrollo \textit{Pythonic} y ofrece un ventaja lógica: el mismo lenguaje de ejecución y compilación.

Se ha decidido utilizar este framework por la facilidad de uso, y la potencia que posee sin configuración previa. Django posee integrado, desde el primer momento, aspectos avanzados de seguridad (evita inyecciones SQL, validaciones de los formularios, autenticación en cada página, entre otros), gestión en cada momento de las sesiones, así como la transparencia en multitud de aspectos: la base de datos utilizada, la localización de los archivos estáticos, el despliegue\dots

\subsubsection{Librerías}
Los módulos son gestionados por Python a través del CLI \textit{pip}. Estos se añaden automáticamente al software a través de esta herramienta y se albergan donde elija el usuario: carpeta de desarrollo o en el sistema. Además, es posible guardar una traza de las versiones usadas para replicar la arquitectura en otro sistema en un fichero de configuración: \textit{requirements.txt}.

Las librerías que han sido necesarias para cumplir los requisitos son las indicadas a continuación:

\begin{itemize}
    \item \textbf{django-rest-framework}: es la herramienta que permite ofrecer una API desde Django. Esta convierte las vistas del framework en un endpoint para publicitar contenido, accesible a través de los verbos HTTP.
    \item \textbf{django-rest-auth}: ofrece, sobre la API implementada, una capa de autenticación usando el modelo de usuarios de Django. Provee diferentes técnicas de registro, dando la posibilidad de usar redes sociales para ello, además de hacer posible el acceso a la información completa de los usuarios.
    \item \textbf{django-cron}: crea operaciones que se ejecutan sobre el CLI propio de Django para poder ser ejecutadas de manera recurrente. Estos métodos interaccionarán con todos los módulos de framework, haciéndolo útil para implementar operaciones \textit{cron}.
    \item \textbf{gunicorn}: es un servidor HTTP que soporta WSGI. Este ofrece a través de peticiones HTTP las aplicaciones de Django. 
    \item \textbf{beautifulsoup}: es una herramienta que permite tratar con archivos HTML de manera programática para extraer información.
    \item \textbf{feedparser}: permite descargar y parsear todo tipo de Feed RSS. Además, es compatible con muchos de los formatos de sindicación: desde RSS 0.9 hasta RSS 2.0; desde Atom 0.3, hasta Atom 1.0.
    \item \textbf{newspaper3k}: es una herramienta de obtención de noticias. Dada una dirección URI, analiza la web y calcula la localización del contenido principal y los metadatos asociados. Además, soporta la mayoría de lenguajes principales y posee herramientas de Procesamiento de Lenguaje Natural en algunos idiomas.
    \item \textbf{python-dateutil}: facilita el tratamiento con fechas en Python y su conversión a diferentes formatos.
\end{itemize}

Para elegir cada una, se ha realizado un pequeño estudio entre sus posibles alternativas. El resumen de esta investigación arroja la siguiente conclusión: son módulos enormemente usados en su mayoría, por lo que cada uno de ellos se ha convertido en la referencia en su tema. Es por ello que rara vez hay alguna alternativa de la misma embergadura que haga dudar al desarrollador a su elección.

\subsection{Frontend}
Para la construcción de la interfaz de usuario se ha escogido JavaScript y el framework de desarrollo VueJS.

\subsubsection{JavaScript}
Desde el inicio del desarrollo web hasta hoy en día solo han existido tres lenguajes en el mundo del frontend: HTML, CSS y JS. El primero para la estructuración de la información, el segundo para el diseño y el tercero para la interacción del usuario y como puente entre ambos. Es sobre este tercero donde mayores avances ha habido a lo largo de los años.

Ni que decir tiene que JavaScript se ha convertido en el lenguaje de referencia en el desarrollo web si se quiere una interfaz desacoplada, asíncrona y elegante, como revela la encuesta mundial de \citeA{state_js}. Son estos los motivos por los que se ha escogido como lenguaje de desarrollo del lado del cliente.

De hecho, si se quiere realizar una \textit{Single Page Application} (SPA en adelante), no hay otra opción plausible. Con  dicha técnica es posible tener un simple fichero HTML e ir interactuando con él a través de JavaScript exclusivamente. Esto da al usuario una visión limpia y rápida de la aplicación en cuestión, con navegabilidad directa y sin interrupciones.

Se ha utilizado este sobre otros lenguajes de alto nivel basados en JavaScript como TypeScript o Flow por su sencillez y recomendaciones de las herramientas utilizadas.

\subsubsection{VueJS}

Una vez decidido que se pretende realizar un frontend desacoplado del lado del servidor, solo queda la elección del framework a utilizar. Realmente, esta decisión en nuestros días se reduce a tres posibles alternativas: React, Angular y VueJS. Esa afirmación se basa en los datos y dirección de la comunidad, como se puede observar en el ya citado \citeA{state_js}.

Si se observa, aparecen, junto a estos tres, dos framework en cuanto a utilización actual: VanillaJS y AngularJS. Sin embargo, estos dos van quedando en desuso en cuanto a framework frontend de una aplicación web como tal. VanillaJS utiliza JavaScript en su estado puro, por lo que, realmente, no se le puede considerar un framework; consiste en una librería con el \textit{core} de JavaScript y se usa cuando se quiere máxima velocidad y mínimo espacio. AngularJS, por su parte, es el predecesor de Angular (también conocido como Angular 2). Cambia por completo su funcionamiento y arquitectura, siendo esta primera versión una librería y la segunda y posteriores, un framework. Google, autor del mismo, ha dejado de actualizar AngularJS, por lo que no ha de tenerse en cuenta para desarrollos actuales.

Visto lo anterior, comparemos los tres frameworks mencionados para ilustrar el motivo de elegir VueJS sobre los demás. Dichos datos y afirmaciones son frutos del artículo de estudio del tema realizado por \citeA{frameworks_js}.

\begin{itemize}
    \item \textbf{React}: es la librería de Facebook centrada en la creación de vistas. Su gran virtud son los patrones de eventos, ya que estos permiten actualizar en tiempo real las vistas con los datos. Realmente no es un framework, por lo que es posible utilizarlo anexo a Angular o VueJS. Sin embargo, debido a su potencial, puede ser usado exclusivamente para realizar la capa de presentación.
    \item \textbf{Angular}: es el framework de Google diseñado sobre su primera versión, anteriormente mencionado, y hecho para ser totalmente independiente y funcional. Usando HTML, CSS y TypeScript consigue crear vistas, componentes independientes y rutas, todas relacionados entre sí. Trabaja sobre el concepto \textit{Single Page Application} (SPA) utilizado para ello Webpack. Este empaquetador, una vez desarrollada la aplicación, agrupa el código en un fichero HTML (\textit{index.html}), un fichero CSS y varios ficheros JS que interaccionarán entre sí.
    \item \textbf{VueJS}: es el framework mantenido por la comunidad que une las ventajas de los desarrollos anteriores, a destacar: el ciclo de vida de los componentes, propio de React, y las directivas de Angular. La curva de aprendizaje es más reducida que Angular y el código resultante poseerá menos ficheros que este, ya que aglutina HTML, CSS y JS en un fichero de extensión \textit{.vue}. Además, es totalmente versátil: se puede utilizar como librería para un desarrollo pequeño hasta como framework en un aplicación SPA o SSR completa.
\end{itemize}

Son estos últimos motivos los que han llevado a optar por VueJS. Además, el ecosistema que ofrece Vue, como se verá en el siguiente punto, es único.

\subsubsection{Librerías}

Los módulos usados están relacionados con el ecosistema que ofrece Vue así como por la comunidad de JavaScript. Estos se gestionan a través de \textit{npm} o \textit{yarn} y al igual que ocurría con \textit{pip}, condensa la información en un fichero para replicar la infraestructura: \textit{package.json}.

\begin{itemize}
    \item \textbf{vue-router}: gestiona la navegabilidad entre las vistas, compartiendo datos entre sí y haciéndolas accesibles desde la URL del navegador.
    \item \textbf{vuex}: administra los estados de determinados objetos a lo largo de toda la aplicación. Ofrece de manera general un almacén de estados que pueden ser mutados y consultados desde cualquier módulo.
    \item \textbf{vuetify}: implementa un ecosistema basado en Material Design, el diseño propuesto por Google, usado componentes Vue.
    \item \textbf{axios}: gestiona las peticiones HTTP en JavaScript ofreciendo una API completa y simple.
    \item \textbf{moment}: convierte cualquier campo de tipo fecha al formato deseado por el usuario.
\end{itemize}

Todas estas librerías son usadas por la gran mayoría de la comunidad y no poseen alternativas claras y robustas: los desarrolladores prefieren mejorarlas a enfrentarse a ser competencia directa.

\subsection{Servidor}

En este apartado se mencionarán las tecnologías usadas en la parte del servidor, de manera conjunta a las de Cliente y Servidor previamente mencionadas.

\subsubsection{PostgreSQL}

Es imprescindible usar en este tipo de proyectos una base de datos consistente. Además, dada la naturaleza de la aplicación en cuestión, esta ha de ser Relacional. De todas las posibilidades que ofrece este gran mundo, Django recomienda usar esta debido a su naturaleza y fuerte interconexión.

Postgres es un sistema gestor de base de batos de tipo relacional, como se ha dicho. Posee una gran escalabilidad, al usar una infraestructura propia de paralelización: multiprocesos en vez de multihilos. Esto implica que desacopla los posibles errores propios de la gestión de hilos, como son las condiciones de carrera.

\subsubsection{Elasticsearch}

Para implementar la Búsqueda y Recuperación de Información, descrito en el punto \ref{sec:tecnologias}, referente a las tecnologías, es necesario usar un Índice.

Elasticsearch es un servidor de búsqueda, distribuido y accesible a través de una interfaz de tipo RESTful. Está desarrollado en Java, basándose en Lucene y es de código abierto. Propone una sintaxis basada en JSON para las búsquedas.

Se ha decidido usar sobre Índice como Algolia o Solr por dos motivos principales. El primero se debe a su coste, nulo en proyectos con implantación propia de dicha herramienta. El segundo es que se está poniendo a la cabeza en el desarrollo de índices generales en la comunidad.

\subsubsection{Nginx}

Una vez albergado y desarrollada la aplicación, es necesario hacerla accesible a través de Internet de manera segura y consistente. Para ello nos hace falta un servidor web o proxy inverso. Las dos grandes alternativas en este punto son Nginx y Apache.

Nginx es un tipo de servidor web ligero y con alto rendimiento. Es open source y permite, además, integración de servidor SMTP, así como soporte de HTTP, HTTP2, IPv6 y demás protocolos.

Se ha decidido usar este por el gran rendimiento que ofrece sobre el Servidor HTTP Apache. Por otra parte, ofrece una gran comunicación y facilidad en la configuración en aplicaciones Full Stack.

\subsubsection{Docker}

Para hacer toda esta arquitectura independiente a cualquier sistema y con la configuración similar a entornos de desarrollo y producción es necesaria la virtualización de los servicios. Esto ha marcado un nuevo hito en el mundo del software: la abstracción entre sistemas operativos y la concentración de la configuración en un único fichero. Esto es Docker.

Docker automatiza el despliegue de cualquier software en contenedores. Estos poseerán toda la configuración que necesita el desarrollo para funcionar. Es la evolución de la máquina virtual: se convierten en instancias Linux ligeras y aisladas.

Actualmente, no hay una alternativa clara a Docker. De hecho, tecnologías de orquestación de contenedores, tales como Swarm o Kubernetes, se basan en esta.

\subsection{Gestión}

En cuanto a la gestión del proyecto se refiere, podemos hablar de dos grandes ámbitos: desarrollo y seguimiento del proyecto.

\subsubsection{Desarrollo}

Para el desarrollo del proyecto han sido necesarias las herramientas que se mencionarán adelante. La preferencia general de dicha elección se basa en dos premisas. La primera es la orientación de la comunidad del desarrollo y la segunda es la disponibilidad real de dichas herramientas. Además de utilizar tecnologías gratuitas, la universidad nos ofrece plataformas y programas en periodo de prueba.

En primer lugar son necesarios los programas para el desarrollo de las diferentes partes de la aplicación. Dado que cada módulo se desarrolla en un lenguaje concreto, se ha apostado por usar IDEs personalizados. Así, y debido a su potencial, se han usado todos aquellos necesarios creados por JetBrains. En el caso de no existir, se ha decidido acudir a Visual Studio Code.

Se ha usado también una herramienta para la realización de diagramas llamada Astah. Esto permite analizar lo que se necesita antes de implementarlo. Gracias a esta se harán todo tipo de diagramas: desde estados hasta clases. Se ha usado esta gracias a su gratuidad a estudiantes.

Para mantener una trazabilidad y respaldo del código, se han usado tecnologías de control de versiones. En concreto, la elegida ha sido Git, debido a su posición en la comunidad del desarrollo y a su funcionalidad y robustez. La plataforma remota donde se alojará dicho código sobre Git es GitHub. Ha sido elegida por ser la principal usada por la comunidad.

En cuanto a la comunicación y despliegue por el servidor, se ha elegido como VPS: Digital Ocean. Posee un enorme potencial y un periodo de prueba más que suficiente para la distribución de la aplicación. Además, para la comunicación con este, se ha usado WinSCP y PuTTY, como herramientas SSH principalmente usadas en Windows.

\subsubsection{Seguimiento}

Una vez llegado a las decisiones convenientes para desarrollar el producto, es necesario seguir una serie de pautas, marcarse unos hitos y tener la posibilidad de comprobar el avance del proyecto. Así, han de usarse una serie de herramientas para medir la evolución y seguir con acierto.

Se han usado grosso modo dos: Toggl para la gestión del tiempo y Waffle para la gestión de las tareas. La primera permite comprobar las horas que lleva cada tarea. Esta permite etiquetar cada una, por lo que se podrá comprobar el tiempo dedicado a cada tipo de tarea (gestión, documentación, desarrollo, despliegue o investigación), así como el total dedicado al proyecto. Con la segunda se consigue agrupar las tareas en hitos y asociarlos a funcionalidades dentro del código. Además, ambas están relacionadas, por lo que simplifica dicha gestión, siendo esta la principal motivación para su uso.

Waffle es la implementación concreta del tablero canvas mencionado en el punto \ref{sec:metodologia_lean}. Si se aprecia la imagen \ref{fig:scrum_github}, vemos que es GitHub la plataforma mencionada para el tablero. Lo ocurrido se puede apreciar en el artículo de \citeA{waffle}. Esta herramienta deja de mantenerse por falta de recursos y recomienda su migración a GitHub.

\section{Estructura del proyecto}\label{sec:estructra_proyecto}

Como se ha ido diciendo a lo largo del documento, el proyecto utiliza Git. Así, se ha estructurado el trabajo en ramas según la metodología Git Flow. Este estructura el cualquier proyecto software con cinco ramas principales:

\begin{itemize}
    \item \textbf{master}: el código en esta rama es la versión estable y funcional que se encuentra funcionando en producción.
    \item \textbf{hostfix}: cualquier fallo detectado en producción se arregla aquí y se lleva a \textit{master} una vez solucionado: no antes.
    \item \textbf{release}: sobre los cambios agrupados del desarrollo, se prueba integralmente antes de ser subidos a \textit{master}.
    \item \textbf{development}: agrupa los cambios en las diferentes características que se van trabajando.
    \item \textbf{feature}: cada una de las funcionalidades a añadir en el sistema.
\end{itemize}

Esto se puede ver gráficamente en la siguiente imagen.

\figura{0.75}{img/estructura/git_flow}{\textit{Git Flow}}{fig:git_flow}{}

Teniendo esto en cuenta, se mostrará cómo se ha estructura cada repositorio de manera general en GitHub, para luego descender, de manera individual, a cada uno.

\subsection{GitHub}

De manera general, se poseen estos repositorios de proyectos en la plataforma de código abierto GitHub. Cada uno de los cuales alberga un desarrollo concreto.

\figura{0.75}{img/estructura/github_repositories}{Respositorios en GitHub}{fig:github_repositories}{}

Los repositorios que muestra la imagen son los siguientes:

\begin{itemize}
    \item \textbf{ltnews-documents}: es el proyecto LaTeX donde se desarrollan los documentos a presentar, tanto la presente memoria como la presentación del trabajo.
    \item \textbf{ltnews-docker}: alberga la arquitectura de la aplicación en docker y se relaciona con los demás repositorios de código.
    \item \textbf{ltnews-backend}: es el proyecto de Django para el servidor de la aplicación.
    \item \textbf{ltnews-frontend}: es la capa de presentación de la aplicación
     realizada en VueJS.
\end{itemize}

Gracias a la integración que realiza GitHub, se ha añadido metacontenido a los commits que se van realizando. En concreto, se han utilizado tres entidades: \textit{issues}, \textit{labels} y \textit{milestones}.

\figura{0.5}{img/estructura/github_issues}{\textit{Issues} en Github}{fig:github_issues}{}

Del primero, los \textit{issues}, comentar que GitHub permite usar esta como una herramienta integrada de gestión de incidencias. Como aparece en la siguiente imagen, cada \textit{issue} viene relacionado con: proyectos, hitos, encargado o etiqueta. Además, posee una traza de comentarios y commits relacionados. Es este el motivo de su uso como gestor de tareas del proyecto.

\figura{0.5}{img/estructura/github_labels}{\textit{Labels} en Github}{fig:github_labels}{}

A la vez, como se ha dicho, se pueden utilizar diferentes etiquetas para relacionar las incidencias. Estas son las que aparecen en la imagen \ref{fig:github_labels}. La idea general es poder clasificar cada tarea según su entidad correspondiente: plataforma relacionada o tipo de tarea. De esta manera, es fácilmente clasificable cada una de las tareas.

\figura{0.5}{img/estructura/github_milestones}{\textit{Milestones} en Github}{fig:github_milestones}{}

En la última entidad, se agrupan también las tareas o \textit{issues} en hitos, llamadas \textit{milestones}. Esto sirve para indicar las fases del proyecto y la fecha de finalización de cada sprint.

A nivel más operativo, que un repositorio esté en GitHub conlleva a que estén presentes los siguientes archivos:

\begin{itemize}
    \item \underline{.gitignore}: es el archivo que contiene los elementos que deberá ignorar git en su proceso de control de versiones.
    \item \underline{LICENCE}: es la licencia del proyecto, que en el presente caso es MIT Licence: esta es una licencia de software permisiva, que posee pocas limitaciones en la reutilización.
    \item \underline{README.md}: contiene la información imprescindible del proyecto que aparecerá reflejada en GitHub.
\end{itemize}

\subsection{Backend}

En cuanto al código del servidor, se ha estructurado el código siguiendo las pautas recomendadas tanto por Python, como por Django. Así, la estructuración en carpetas es la que aparece en la imagen \ref{fig:estructura_pycharm}. Está se irá desgranando para explicar su lógica.

\figura{}{img/estructura/estructura_pycharm}{Estructura en PyCharm}{fig:estructura_pycharm}{}

\begin{itemize}
    \item \textbf{ltnews}: contiene la lógica de funcionamiento de Django.
    \begin{itemize}
        \item \underline{cron.py}: archivo que contiene las tareas recurrentes de la aplicación, entre ellas, la que actualiza las noticias y la que calcula el perfil del usuario.
        \item \underline{settings.py}: archivo que contiene las propiedades principales de nuestra aplicación.
        \item \underline{urls.py}: archivo con los accesos a las direcciones accesibles a nuestro proyecto; relaciona controlador con url.
        \item \underline{wsgi.py}: archivo que tiene la información y propiedades del despliegue del servidor Django.
    \end{itemize}
    \item \textbf{news}: contiene la lógica de la aplicación implementada.
    \begin{itemize}
        \item \textbf{migrations}: contiene las migraciones hechas del modelo de Django.
        \item \textbf{service}: contiene los servicios de las entidades por cada entidad del modelo y son intermediarios entre el modelo y el controlador, ya que extraen la información de la base de datos ya ordenada y útil de utilizar en los controladores.
        \item \textbf{test}: contiene los tests agrupados en las entidades del sistema.
        \item \textbf{utility}: contiene las clases de utilidad que han sido necesarias desarrollar la el correcto funcionamiento del sistema.
        \item \textbf{view}: contiene los controladores por entidad, en concreto, la implementación de cada API publicada.
        \item \underline{admin.py}: archivo en el que se declara el nombre de las entidades del sistema.
        \item \underline{apps.py}: archivo con nombre y características de la aplicación.
        \item \underline{documents.py}: archivo que contiene la comunicación de Elasticsearch con la aplicación así como la implementación de los documentos.
        \item \underline{models.py}: archivo que contiene las entidades del modelo.
        \item \underline{serializers.py}: archivo que contiene la implementación de serialización de cada entidad del modelo a través de la API.
        \item \underline{services.py}: archivo con los servicios genéricos que usan todas las entidades.
        \item \underline{tests.py}: archivos que contiene las pruebas generales del sistema.
    \end{itemize}
    \item \textbf{static}: alberga los ficheros estáticos generados para el panel de administración.
    \item \underline{.travis.yml}: los comandos que se ejecutarán en la herramienta de pruebas de integración continua Travis.
    \item \underline{manage.py}: es el archivo principal de Django, el archivo de ejecución principal.
    \item \underline{requirements.txt}: contiene todos los componentes que usa el proyecto de Python, así como sus versiones.
\end{itemize}

\subsection{Frontend}

El código del cliente se estructura siguiendo las directrices del CLI de Vue. Estas no son más que una implementación concreta y ordenada de las pautas de Node y Webpack. Así, la organización se muestra en la imagen \ref{fig:estructura_webstorm}.

\figura{}{img/estructura/estructura_webstorm}{Estructura en WebStorm}{fig:estructura_webstorm}{}

\begin{itemize}
    \item \textbf{dist}: contiene la construcción de la aplicación en formato SPA realizada por \textit{npm} o \textit{yarn}.
    \item \textbf{node\_modules}: contiene los paquetes necesarios por \textit{npm} para la construcción y ejecución de la aplicación.
    \item \textbf{public}: contiene los ficheros globales de la aplicación tales como el índice o el favicon.
    \item \textbf{src}: contiene la lógica general de la aplicación siguiendo la estructuración de Webpack.
    \begin{itemize}
        \item \textbf{api}: contiene las llamadas generales a la API y la configuración de estas por \textit{axios}.
        \item \textbf{assets}: contiene las imágenes y ficheros estáticos usados por la aplicación.
        \item \textbf{components}: contiene los componentes de la aplicación: estos funcionan de manera independiente y pueden ser usados en cualquier vista.
        \item \textbf{plugins}: contiene la configuración de algunos módulos usados por la aplicación, como en el caso de \textit{Vuetify}.
        \item \textbf{stores}: contiene la configuración de estados de las diferentes entidades creadas; don gestionadas por \textit{vuex}.
        \item \textbf{views}: contiene las vistas que posee la aplicación con la lógica implementada en cada una.
        \item \underline{App.vue}: archivo con la arquitectura visual que presenta la aplicación.
        \item \underline{main.js}: archivo con la configuración general de la aplicación Vue.
        \item \underline{router.js}: archivo con la navegabilidad entre las diferentes vistas así como su relación con las URLs.
        \item \underline{store.js}: archivo con la relación de estados y mutaciones especificados en la carpeta \textbf{stores}.
    \end{itemize}
    \item \underline{babel.config.js}: archivo con la configuración de Babel.
    \item \underline{package.json}: archivo con el fichero de configuración de la aplicación con la información general y de librerías necesarias y uso específico de estas.
    \item \underline{yarn.lock}: archivo con la configuración generada por las herramientas de node antes mencionadas.
\end{itemize}